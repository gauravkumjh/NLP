{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>id</th>\n",
       "      <th>replyToUID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:40:30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014957e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>HASHTAGFARZIWAL</td>\n",
       "      <td>331</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:40:29</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014957e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>PRAMODKAUSHIK9</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:40:03</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014955e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>rahulja13034944</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:39:59</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014955e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>deeptiyvd</td>\n",
       "      <td>338</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:39:39</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014954e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://cpimharyana.com\" rel=\"nofollow...</td>\n",
       "      <td>CPIMBadli</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  X                                               text  \\\n",
       "0           1  1  RT @rssurjewala: Critical question: Was PayTM ...   \n",
       "1           2  2  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "2           3  3  RT @roshankar: Former FinSec, RBI Dy Governor,...   \n",
       "3           4  4  RT @ANI_news: Gurugram (Haryana): Post office ...   \n",
       "4           5  5  RT @satishacharya: Reddy Wedding! @mail_today ...   \n",
       "\n",
       "   favorited  favoriteCount replyToSN              created  truncated  \\\n",
       "0      False              0       NaN  2016-11-23 18:40:30      False   \n",
       "1      False              0       NaN  2016-11-23 18:40:29      False   \n",
       "2      False              0       NaN  2016-11-23 18:40:03      False   \n",
       "3      False              0       NaN  2016-11-23 18:39:59      False   \n",
       "4      False              0       NaN  2016-11-23 18:39:39      False   \n",
       "\n",
       "   replyToSID            id  replyToUID  \\\n",
       "0         NaN  8.014957e+17         NaN   \n",
       "1         NaN  8.014957e+17         NaN   \n",
       "2         NaN  8.014955e+17         NaN   \n",
       "3         NaN  8.014955e+17         NaN   \n",
       "4         NaN  8.014954e+17         NaN   \n",
       "\n",
       "                                        statusSource       screenName  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...  HASHTAGFARZIWAL   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...   PRAMODKAUSHIK9   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...  rahulja13034944   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...        deeptiyvd   \n",
       "4  <a href=\"http://cpimharyana.com\" rel=\"nofollow...        CPIMBadli   \n",
       "\n",
       "   retweetCount  isRetweet  retweeted  \n",
       "0           331       True      False  \n",
       "1            66       True      False  \n",
       "2            12       True      False  \n",
       "3           338       True      False  \n",
       "4           120       True      False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the data\n",
    "import pandas as pd\n",
    "#The tweets dataset contains tweets about demonetization in 2016\n",
    "tweets = pd.read_csv('tweets.csv', encoding='ISO-8859-1')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RT @rssurjewala: Critical question: Was PayTM ...\n",
       "1    RT @Hemant_80: Did you vote on #Demonetization...\n",
       "2    RT @roshankar: Former FinSec, RBI Dy Governor,...\n",
       "3    RT @ANI_news: Gurugram (Haryana): Post office ...\n",
       "4    RT @satishacharya: Reddy Wedding! @mail_today ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing the data\n",
    "##Cleaning the data\n",
    "\n",
    "import string\n",
    "punctuation = string.punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def _clean(text):\n",
    "    #Lower casing\n",
    "    text = text.lower()\n",
    "    #Removing punctuations\n",
    "    text = ''.join(x for x in text if x not in punctuation)\n",
    "    words = text.split()\n",
    "    #Removing stopwords\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample text'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_clean('this is a sample text !!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying the _clean function\n",
    "tweets['cleaned'] = tweets['text'].apply(lambda x: _clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>rt rssurjewala critical question paytm informe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>rt hemant80 vote demonetization modi survey app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>rt roshankar former finsec rbi dy governor cbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
       "      <td>rt aninews gurugram haryana post office employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>rt satishacharya reddy wedding mailtoday carto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  RT @rssurjewala: Critical question: Was PayTM ...   \n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor,...   \n",
       "3  RT @ANI_news: Gurugram (Haryana): Post office ...   \n",
       "4  RT @satishacharya: Reddy Wedding! @mail_today ...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  rt rssurjewala critical question paytm informe...  \n",
       "1    rt hemant80 vote demonetization modi survey app  \n",
       "2  rt roshankar former finsec rbi dy governor cbd...  \n",
       "3  rt aninews gurugram haryana post office employ...  \n",
       "4  rt satishacharya reddy wedding mailtoday carto...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View of raw text and clean version\n",
    "tweets[['text','cleaned']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis\n",
    "#Keywords\n",
    "#Phrases\n",
    "#People mentioned\n",
    "#Hashtags\n",
    "#URLS/emails\n",
    "#Person names/company names\n",
    "#Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('demonetization', 13939),\n",
       " ('rt', 11059),\n",
       " ('india', 2766),\n",
       " ('modi', 2759),\n",
       " ('pm', 2729),\n",
       " ('narendra', 1566),\n",
       " ('rich', 1509),\n",
       " ('find', 1422),\n",
       " ('dear', 1411),\n",
       " ('implement', 1399),\n",
       " ('evanspiegel', 1389),\n",
       " ('actually', 1374),\n",
       " ('amp', 1302),\n",
       " ('urautelaforever', 1273),\n",
       " ('narendramodi', 1162),\n",
       " ('people', 1092),\n",
       " ('bank', 1029),\n",
       " ('rs', 740),\n",
       " ('impact', 701),\n",
       " ('cash', 697),\n",
       " ('lakh', 686),\n",
       " ('support', 684),\n",
       " ('terrorists', 658),\n",
       " ('youtube', 642),\n",
       " ('jampk', 638),\n",
       " ('since', 596),\n",
       " ('nation', 594),\n",
       " ('thats', 581),\n",
       " ('move', 553),\n",
       " ('third', 552),\n",
       " ('40', 550),\n",
       " ('looted', 547),\n",
       " ('incident', 547),\n",
       " ('kishtwar', 544),\n",
       " ('modibharosa', 543),\n",
       " ('gauravcsawant', 541),\n",
       " ('money', 512),\n",
       " ('question', 507),\n",
       " ('back', 499),\n",
       " ('across', 453),\n",
       " ('atms', 449),\n",
       " ('like', 442),\n",
       " ('says', 401),\n",
       " ('due', 401),\n",
       " ('supports', 393),\n",
       " ('goes', 376),\n",
       " ('paytm', 374),\n",
       " ('drkumarvishwas', 358),\n",
       " ('https', 354),\n",
       " ('mru092du093eu0935u0941u0915', 353)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "complete_text = ' '.join(tweets['cleaned'])\n",
    "words = complete_text.split()\n",
    "Counter(words).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@evanspiegel', 1306),\n",
       " ('@URautelaForever:', 1273),\n",
       " ('@narendramodi', 1109),\n",
       " ('@gauravcsawant:', 541),\n",
       " ('@ModiBharosa:', 539),\n",
       " ('@DrKumarVishwas:', 350),\n",
       " ('@5Forty3:', 285),\n",
       " ('@rahulroushan:', 280),\n",
       " ('@rssurjewala:', 280),\n",
       " ('@centerofright:', 237),\n",
       " ('@PMOIndia', 237),\n",
       " ('@ShashiTharoor:', 210),\n",
       " ('@DasShaktikanta', 195),\n",
       " ('@steve_hanke:', 176),\n",
       " ('@ashu3page:', 170),\n",
       " ('@kanimozhi:', 152),\n",
       " ('@AskAnshul:', 149),\n",
       " ('@RoflGandhi_:', 147),\n",
       " ('@YouTube', 145),\n",
       " ('@Timcast:', 137),\n",
       " ('@Atheist_Krishna:', 133),\n",
       " ('@', 132),\n",
       " ('@ArvindKejriwal', 130),\n",
       " ('@Joydas:', 113),\n",
       " ('@arunjaitley', 112),\n",
       " ('@ippatel:', 110),\n",
       " ('@jamewils:', 105),\n",
       " ('@FinMinIndia', 104),\n",
       " ('@Joydeep_911:', 102),\n",
       " ('@attomeybharti:', 101),\n",
       " ('@PIB_India:', 97),\n",
       " ('@PiyushGoyalOffc:', 95),\n",
       " ('@Memeghnad', 84),\n",
       " ('@DrGPradhan:', 83),\n",
       " ('@priyaakulkarni2:', 80),\n",
       " ('@MIB_India:', 79),\n",
       " ('@minimathur', 79),\n",
       " ('@dna:', 76),\n",
       " ('@Ra_THORe:', 75),\n",
       " ('@pGurus1:', 74),\n",
       " ('@_MiteshPatel:', 73),\n",
       " ('@aaanupriyaaa:', 70),\n",
       " ('@aartic02:', 69),\n",
       " ('@NG_withINC:', 68),\n",
       " ('@jairajp:', 62),\n",
       " ('@Hemant_80:', 62),\n",
       " ('@na', 59),\n",
       " ('@harshkkapoor:', 58),\n",
       " ('@ShirishKunder:', 54),\n",
       " ('@anandkamal', 54)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keyword analysis performs a very high level analysis\n",
    "# From keyword analysis we found demonetisation is the highest used keyword.\n",
    "# It is obvious as the dataset contains the demonetization tweets.\n",
    "# Lets find the maximum number of mentions\n",
    "\n",
    "raw_text = \" \".join(tweets['text'])\n",
    "mentions = [word for word in raw_text.split() if word.startswith('@')]\n",
    "Counter(mentions).most_common(50)\n",
    "\n",
    "#From mentions we can see, some politicians as well as some celebrities tops the mention list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#Demonetization', 3253),\n",
       " ('#demonetization', 2474),\n",
       " ('#DeMonetization', 742),\n",
       " ('#demonetization.', 713),\n",
       " ('#India', 295),\n",
       " ('#nitishkumar', 257),\n",
       " ('#Demonetization:', 243),\n",
       " ('#Demonetization.', 192),\n",
       " ('#demo', 174),\n",
       " ('#DeMonetization.', 157),\n",
       " ('#GLvMI', 145),\n",
       " ('#demonetization,', 137),\n",
       " ('#CorruptionFreeIndia', 103),\n",
       " ('#Demonetization,', 94),\n",
       " ('#BlackMoney', 91),\n",
       " ('#VijayMallya', 86),\n",
       " ('#IndiaFightsCorruption', 79),\n",
       " ('#Modi', 67),\n",
       " ('#DEMONETIZATION', 59),\n",
       " ('#NoMoneyYaar', 53),\n",
       " ('#BJP', 50),\n",
       " ('#Demonetizat', 47),\n",
       " ('#SonuNigam', 47),\n",
       " ('#bulletin', 44),\n",
       " ('#RatanTata', 44),\n",
       " ('#Insights', 44),\n",
       " ('#boycottsnapchat', 43),\n",
       " ('#DeMonetisation', 42),\n",
       " ('#RBI', 42),\n",
       " ('#demonetization?', 42),\n",
       " ('#LifeInsurance', 34),\n",
       " ('#Demonetization.(2016)', 32),\n",
       " ('#demonetisation', 31),\n",
       " ('#YouTubeIsDead', 30),\n",
       " ('#NMApp', 29),\n",
       " ('#MeraDeshBadalRaha', 28),\n",
       " (\"#India's\", 27),\n",
       " ('#PMModi', 25),\n",
       " ('#news', 25),\n",
       " ('#NarendraModi', 25),\n",
       " ('#TrustBJP', 25),\n",
       " ('#CGDTalks', 23),\n",
       " ('#not', 23),\n",
       " ('#Hilarious.', 20),\n",
       " ('#Hitler', 20),\n",
       " ('#lifehacks', 19),\n",
       " ('#india', 18),\n",
       " ('#PM', 18),\n",
       " ('#ITVideo', 18),\n",
       " ('#demonetization:', 18)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check for top hastags\n",
    "raw_text = \" \".join(tweets['text'])\n",
    "hashtags = [word for word in raw_text.split() if word.startswith('#')]\n",
    "Counter(hashtags).most_common(50)\n",
    "\n",
    "#The most used word with # is Demonetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#India', 295),\n",
       " ('#nitishkumar', 257),\n",
       " ('#GLvMI', 145),\n",
       " ('#CorruptionFreeIndia', 103),\n",
       " ('#BlackMoney', 91),\n",
       " ('#VijayMallya', 86),\n",
       " ('#IndiaFightsCorruption', 79),\n",
       " ('#Modi', 67),\n",
       " ('#NoMoneyYaar', 53),\n",
       " ('#BJP', 50),\n",
       " ('#SonuNigam', 47),\n",
       " ('#bulletin', 44),\n",
       " ('#RatanTata', 44),\n",
       " ('#Insights', 44),\n",
       " ('#boycottsnapchat', 43),\n",
       " ('#RBI', 42),\n",
       " ('#LifeInsurance', 34),\n",
       " ('#YouTubeIsDead', 30),\n",
       " ('#NMApp', 29),\n",
       " ('#MeraDeshBadalRaha', 28),\n",
       " (\"#India's\", 27),\n",
       " ('#news', 25),\n",
       " ('#NarendraModi', 25),\n",
       " ('#PMModi', 25),\n",
       " ('#TrustBJP', 25),\n",
       " ('#CGDTalks', 23),\n",
       " ('#not', 23),\n",
       " ('#Hilarious.', 20),\n",
       " ('#Hitler', 20),\n",
       " ('#lifehacks', 19),\n",
       " ('#india', 18),\n",
       " ('#PM', 18),\n",
       " ('#ITVideo', 18),\n",
       " ('#survey', 18),\n",
       " ('#Doltiwal', 18),\n",
       " ('#JaiChandKejriwal', 18),\n",
       " ('#NetasCASHIn', 17),\n",
       " ('#NoteNahiPMBadlo', 17),\n",
       " ('#IncrementPremierLeague', 17),\n",
       " ('#', 17),\n",
       " (\"#Modi's\", 17),\n",
       " ('#IndiaKaDil.', 17),\n",
       " ('#NorthEast', 17),\n",
       " ('#WarOnCash', 16),\n",
       " ('#Bitcoin', 16),\n",
       " (\"#NarendraModi's\", 16),\n",
       " ('#Snapchat', 16),\n",
       " ('#payments', 16),\n",
       " ('#BSP', 15),\n",
       " ('#YouTube', 15)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting words other than demonetization or its variants\n",
    "hashtags = [word for word in raw_text.split() if word.startswith('#')]\n",
    "hashtags_updated = [word for word in hashtags if 'demo' not in word.lower()]\n",
    "Counter(hashtags_updated).most_common(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://t.co/ObQrhlNSL6', 350),\n",
       " ('https://t.co/UodwXdPMmG', 254),\n",
       " ('https://t', 252),\n",
       " ('https://t.c', 187),\n",
       " ('https:/', 162),\n",
       " ('https://t.co/DGAI5cf05y', 120),\n",
       " ('https://t.co/pYgK8Rmg7r', 114),\n",
       " ('https://t.co/TDj2A6uO5u', 95),\n",
       " ('https://t.co/9NheK63TPg', 91),\n",
       " ('https://t.co/', 90),\n",
       " ('http', 83),\n",
       " ('https://t.co/heTEYUM0ch', 80),\n",
       " ('https:', 76),\n",
       " ('https://t.co/3TP2svF', 73),\n",
       " ('https', 72),\n",
       " ('https://t.co/E', 69),\n",
       " ('https://t.', 60),\n",
       " ('https://t.co/D85BiDMvFM', 47),\n",
       " ('https://t.co/4RMD7Fpfaw', 45),\n",
       " ('https://', 44),\n",
       " ('https://t.co/A8of7zh2f5', 44),\n",
       " ('https://t.co/fRTHY2Ltth', 41),\n",
       " ('https://t.co/NVv7slCcpr', 41),\n",
       " ('https://t.co/X2ME55oPks', 35),\n",
       " ('https://t.co/0fMh3UMbVq', 32),\n",
       " ('https://t.co/T1Agu6CH33', 29),\n",
       " ('https://t.co/P6HkkDVa3b', 28),\n",
       " ('https://g', 27),\n",
       " ('https://t.co/ThzaV7r', 25),\n",
       " ('https://t.co/ePVcU2T38F', 24),\n",
       " ('https://t.co/PK9qO92K4N', 23),\n",
       " ('https://t.co/EqbMve2T2F', 23),\n",
       " ('https://t.co/rLr6wGdeaa', 22),\n",
       " ('https://t.co/Uc6jrbvUNE', 22),\n",
       " ('https://t.co/g', 21),\n",
       " ('https://t.co/IeXuia3J0X', 20),\n",
       " ('https://t.co/DRxxTEw9Zt', 20),\n",
       " ('https://t.co/rng1gKiUgm', 19),\n",
       " ('https://t.co/TAEYsN4yBF', 19),\n",
       " ('https://t.co/FRNAKe7', 19),\n",
       " ('https://t.co', 19),\n",
       " ('https://t.co/LffZzfOKf8', 18),\n",
       " ('https://t.co/62nqWWUgL1', 18),\n",
       " ('https://t.co/rLPk6LPfv3', 17),\n",
       " ('https://t.co/2IiIELPLlf', 16),\n",
       " ('https://t.co/uCS21Uv5G8', 16),\n",
       " ('https://t.co/mMgPS675Uo', 16),\n",
       " ('https://t.co/RiJENeWX7y', 15),\n",
       " ('https://t.co/ejlAIQOs2M', 15),\n",
       " ('https://t.co/sIVo5YMhJp', 14)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the most used links from the data\n",
    "links = [word for word in raw_text.split() if word.startswith('http')]\n",
    "Counter(links).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('narendra', 'modi'), 1565),\n",
       " (('india', 'rich'), 1431),\n",
       " (('pm', 'narendra'), 1424),\n",
       " (('demonetization', 'find'), 1399),\n",
       " (('implement', 'demonetization'), 1397),\n",
       " (('rich', 'pm'), 1391),\n",
       " (('modi', 'implement'), 1376),\n",
       " (('evanspiegel', 'india'), 1371),\n",
       " (('dear', 'evanspiegel'), 1366),\n",
       " (('find', 'actually'), 1311),\n",
       " (('urautelaforever', 'dear'), 1273),\n",
       " (('rt', 'urautelaforever'), 1273),\n",
       " (('actually', 'rt'), 1024),\n",
       " (('pm', 'narendramodi'), 587),\n",
       " (('since', 'demonetization'), 572),\n",
       " (('demonetization', 'thats'), 546),\n",
       " (('lakh', 'looted'), 544),\n",
       " (('looted', 'bank'), 542),\n",
       " (('kishtwar', 'jampk'), 542),\n",
       " (('bank', 'kishtwar'), 542)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets analyze bigrams and trigrams instead of most frequent words\n",
    "from nltk import ngrams\n",
    "bigrams = ngrams(complete_text.split(),2)\n",
    "Counter(bigrams).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ORGANIZATION PM/NNP)\n",
      "(GPE Modi/NNP)\n",
      "(ORGANIZATION RBI/NNP Dy/NNP)\n",
      "(ORGANIZATION CBDT/NNP)\n",
      "(PERSON Harvard/NNP Professor/NNP)\n",
      "(PERSON Aam/NNP Aadmi/NNP)\n",
      "(ORGANIZATION Haryana/NNP)\n",
      "(PERSON Reddy/NNP Wedding/NNP)\n"
     ]
    }
   ],
   "source": [
    "# Lets get the names of people and companies present in the tweets\n",
    "# For that we will use NER\n",
    "import nltk\n",
    "from nltk import word_tokenize,pos_tag,ne_chunk\n",
    "\n",
    "# We will be using raw_text as cleaned may have lose parts of speech tag context as we have removed stopwords\n",
    "for text in tweets['text'].head():\n",
    "    entities = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    for entity in entities:\n",
    "        if hasattr(entity,'label'):\n",
    "            print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.4625, subjectivity=0.6375)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment analysis using textblob\n",
    "from textblob import TextBlob\n",
    "TextBlob('This is a sample where we can say people in this word hate each other.').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.1875, subjectivity=0.4875)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-ve polarity shows negative sentiment and +ve polarity shows positive sentiment\n",
    "TextBlob('This is a sample where we can say people in this word love each other.').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Many opposition leaders are with @narendramodi on the #Demonetization \\r\\nAnd respect their decision,but support opposition just b'coz of party\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(tweets.iloc[10]['text']).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further analysis that can be performed based on tweets from a domain\n",
    "# Descriptive statistics - say to find the source of most of the tweets\n",
    "# Timeseries analysis - We can add timestamp as  a feature and can analyze how the sentiment of people have change over a\n",
    "# particular thing over a period of time\n",
    "# Link with other variables - say we want to find the increase or decrease of mobile phones in corrlation of tweets by \n",
    "# the advertising team on twitter\n",
    "# Recommendation engines - Based on previous searches, we can recommend what to buy\n",
    "# Machine learning - News headlines or twitter activities can be used to estimate changes in stock market\n",
    "# Knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
